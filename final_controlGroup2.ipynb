{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import json\n",
    "import datetime as dt\n",
    "import os\n",
    "from psaw import PushshiftAPI\n",
    "import itertools\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = PushshiftAPI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first post date of each control user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_authors = pd.read_csv(r'D:/ISI REU Python/PSAW Data/Authors Lists/top200_authors.csv')\n",
    "authors_list = df_authors['Authors']\n",
    "authors_set = set(authors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths_s = []\n",
    "\n",
    "for root, directories, files in os.walk(r'D:/ISI REU Python/Authors PSAW (Copy)/'):\n",
    "    for filename in files:\n",
    "        filepath = os.path.join(root, filename)\n",
    "        if '_submissions.json' in filepath:\n",
    "            new_filepath = filepath.replace(r'D:/ISI REU Python/Authors PSAW (Copy)/','').replace('_submissions.json','')\n",
    "            file_paths_s.append(new_filepath)\n",
    "\n",
    "file_paths_s = set(dict.fromkeys(file_paths_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths_c = []\n",
    "\n",
    "for root, directories, files in os.walk(r'D:/ISI REU Python/Authors PSAW (Copy)/'):\n",
    "    for filename in files:\n",
    "        filepath = os.path.join(root, filename)\n",
    "        if '_comments.json' in filepath:\n",
    "            new_filepath = filepath.replace(r'D:/ISI REU Python/Authors PSAW (Copy)/','').replace('_comments.json','')\n",
    "            file_paths_c.append(new_filepath)\n",
    "\n",
    "file_paths_c = set(dict.fromkeys(file_paths_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = file_paths_s.intersection(file_paths_c)\n",
    "set_200authors = authors_set.intersection(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GreatApes = pd.read_csv(r'D:/ISI REU Python/PSAW Data/Full Data/GreatApes_authors.csv',names=['Authors'])\n",
    "set_GreatApes = set(df_GreatApes['Authors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_200authors = list(set_200authors - set_GreatApes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter out users who haven't used a hate word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_words = pd.read_csv(r'D:/ISI REU Python/coontown-manually-filtered-hate-words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "\n",
    "hate_users = []\n",
    "\n",
    "for author in list_200authors:\n",
    "    vernacular = set()\n",
    "    \n",
    "    file_name = \"D:/ISI REU Python/Authors PSAW (Copy)/\"+author+\"_submissions.json\"\n",
    "#     df_s = pd.read_csv(file_name)\n",
    "#     for line in list(df_s['selftext']):\n",
    "#         vernacular.add(line.split())\n",
    "#     for line in list(df_s['title']):\n",
    "#         vernacular.add(line.split())\n",
    "    with open(file_name,'r') as json_file:\n",
    "        for line in json_file:\n",
    "            new_line = json.loads(line)\n",
    "            selftext = new_line['selftext']\n",
    "            if ('selftext' in new_line) and (new_line['selftext'] != None):\n",
    "                for ele in selftext:\n",
    "                    if ele in punc:\n",
    "                        selftext = selftext.replace(ele, \"\")\n",
    "                for word in selftext.split():\n",
    "                    vernacular.add(word)\n",
    "            title = new_line['title']\n",
    "            if ('title' in new_line) and (new_line['title'] != None):\n",
    "                for ele in title:\n",
    "                    if ele in punc:\n",
    "                        title = title.replace(ele,\"\")\n",
    "                for word in title.split():\n",
    "                    vernacular.add(word)\n",
    "    \n",
    "    file_name = \"D:/ISI REU Python/Authors PSAW (Copy)/\"+author+\"_comments.json\"\n",
    "#     df_c = pd.read_csv(file_name)\n",
    "#     for line in list(df_s['body']):\n",
    "#         vernacular.add(line.split())\n",
    "    with open(file_name,'r') as json_file:\n",
    "        for line in json_file:\n",
    "            new_line = json.loads(line)\n",
    "            body = new_line['body']\n",
    "            if ('body' in new_line) and (new_line['body'] != None):\n",
    "                for ele in body:\n",
    "                    if ele in punc:\n",
    "                        body = body.replace(ele,\"\")\n",
    "                for word in body.split():\n",
    "                    vernacular.add(word)\n",
    "    \n",
    "#     print(vernacular)\n",
    "    for word in vernacular:\n",
    "        if word in hate_words:\n",
    "            hate_users.append(author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['advancedatheist', 'AsianGirl69420', 'BaconCatBug', 'accountt1234', 'AegonTheDragon', 'AR96', '75000_Tokkul', 'asmosdeus', 'Andy_p88', 'BerlinSpiderRocket', 'aDildoAteMyBaby', 'BF8211', 'article10ECHR', 'aviary83', 'ARealLibertarian', 'AltaEgoNerd', 'AlexiPwns', 'anymaninamerica', 'Banksykern', 'benjammin9292', 'avian_buddha', 'average_user_421', 'Aziral', 'anubgek', '1Cu14Cu', 'andrewsj1', 'Aquamaniac7', 'Allergic2Antisemites', 'AssuredlyAThrowAway', 'Ant_Sucks', 'ArcherKSI', 'Bert-Goldberg', 'Asis_450', '4LostSoulsinaBowl', '-Damien-', '8works', 'BedWedOrBehead', 'amanitus', 'abigfatphoney', 'Anal_Justice_League', '5th_Law_of_Robotics', 'albro1', 'AlexJuhu', 'Abandon-All-Hope', 'Ago_Solvo', 'ANAL_ANARCHY', 'AntiHasbaraUnit', '360BRoScope420', '27589592958385729', 'americanslang59', '15rthughes', 'ArtGamer', 'banmeagainreddit', 'AllPurposeNerd', 'A_Medium_Pizza', 'Bassoon_Commie', 'acacia-club-road', 'AntonioOfVenice', '2016pantherswin', 'Atlas_B_Shruggin', 'Avery_Richman', 'Baconlightning', 'antoine_chekov', 'BadgerBadger8264', 'BasediCloud', '2PantsLady', 'Alienm00se', 'BananaMeGustaII', 'Arfmeow', 'acratus', 'App1e5auce', 'ACraftyApe', 'AiogbZuyzn', '10BIT', 'ahanix1989', '30plus1', 'alllie', 'AN4RCHID', 'Avron12', 'Anton_Lemieux', 'AverageTheJam', 'arrow74', 'Arxl', 'abertsa', 'andytuba', '100skylines', 'Becomelaced', 'AcradiousPCMR', 'Bhazor', 'Adamex99', '-SnowMan-', 'Backupusername', 'Barely_Intrepid', 'ATN-Antronach', 'ApathyPyramid', 'ArkOrb', 'Ahseyo', 'baconbum', 'bam2_89', 'AssassinAbra', 'A_Wyatt_Guy', 'aaomalley', '1amathrowaway', '---CitationNeeded---', 'Ayy_2_Brute', '-R-TRAIN-', 'BERTRAMUS', 'BestRedditGoy', 'aidsfarts', '-INFOWARS-', 'AristotleJr', '66xsseldoG', '3K-calories', 'Baron-G', 'atomicllama1', '1randomguy', 'acesandspades888', 'Amos_Quito', 'Autsin', 'BevoGenocide', 'AxlWRose', 'AttractiveMeat', 'ArkansasTheAdjective', 'Amunium', 'Badapadawow', 'Apdodopa4', 'Andewz111', 'ArchangellePedophile', 'biga29', 'agentf90', 'bastardfish', '09112001', 'BigDickRichie', 'Ardvarkeating101', 'Balthanos', 'a_horrible_person', 'arbili', 'Alpha-as-fuck', 'BaKdGoOdZ0203', 'adidasaids', 'asoupo', 'aresroth8', 'aj_thenoob', 'thugl1fe', '9DAN2', 'bigDean636', '121381', 'BadGoyWithAGun', 'anicolette', 'antaryon', 'Animal31', 'AnOddSeriesOfTubes', 'ban_collector', 'BaronSathonyx']\n"
     ]
    }
   ],
   "source": [
    "print(hate_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find all important characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gaFirst = pd.read_csv(r'D:/ISI REU Python/Analyzed Data/GreatApes_firstpost.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matched = pd.read_csv(r'D:/ISI REU Python/Analyzed Data/matched_firstpost.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gaFirst = df_gaFirst.rename(columns={'Username':'Username_x','Time (First Post)':'Time (First Post in GA)','Datetime (First Post)':'Datetime (First Post in GA)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username_x</th>\n",
       "      <th>Time (First Post in GA)</th>\n",
       "      <th>Datetime (First Post in GA)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Invalid_Target</td>\n",
       "      <td>1374125927</td>\n",
       "      <td>2013-07-17 22:38:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Finn1916</td>\n",
       "      <td>1377063383</td>\n",
       "      <td>2013-08-20 22:36:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RAPT0RJESUS</td>\n",
       "      <td>1377127936</td>\n",
       "      <td>2013-08-21 16:32:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AlSharptonIsWorthles</td>\n",
       "      <td>1377205625</td>\n",
       "      <td>2013-08-22 14:07:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dayquando</td>\n",
       "      <td>1377212671</td>\n",
       "      <td>2013-08-22 16:04:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3289</th>\n",
       "      <td>purple_monkey58</td>\n",
       "      <td>1436945839</td>\n",
       "      <td>2015-07-15 00:37:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3290</th>\n",
       "      <td>evolapatient</td>\n",
       "      <td>1436968777</td>\n",
       "      <td>2015-07-15 06:59:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3291</th>\n",
       "      <td>GoybeSmaap</td>\n",
       "      <td>1437097935</td>\n",
       "      <td>2015-07-16 18:52:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292</th>\n",
       "      <td>pppk3125</td>\n",
       "      <td>1437135819</td>\n",
       "      <td>2015-07-17 05:23:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3293</th>\n",
       "      <td>Baryshnikov_Rifle</td>\n",
       "      <td>1437578559</td>\n",
       "      <td>2015-07-22 08:22:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3294 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Username_x  Time (First Post in GA)  \\\n",
       "0           Invalid_Target               1374125927   \n",
       "1                 Finn1916               1377063383   \n",
       "2              RAPT0RJESUS               1377127936   \n",
       "3     AlSharptonIsWorthles               1377205625   \n",
       "4                Dayquando               1377212671   \n",
       "...                    ...                      ...   \n",
       "3289       purple_monkey58               1436945839   \n",
       "3290          evolapatient               1436968777   \n",
       "3291            GoybeSmaap               1437097935   \n",
       "3292              pppk3125               1437135819   \n",
       "3293     Baryshnikov_Rifle               1437578559   \n",
       "\n",
       "     Datetime (First Post in GA)  \n",
       "0            2013-07-17 22:38:47  \n",
       "1            2013-08-20 22:36:23  \n",
       "2            2013-08-21 16:32:16  \n",
       "3            2013-08-22 14:07:05  \n",
       "4            2013-08-22 16:04:31  \n",
       "...                          ...  \n",
       "3289         2015-07-15 00:37:19  \n",
       "3290         2015-07-15 06:59:37  \n",
       "3291         2015-07-16 18:52:15  \n",
       "3292         2015-07-17 05:23:39  \n",
       "3293         2015-07-22 08:22:39  \n",
       "\n",
       "[3294 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gaFirst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_gaFirst.merge(df_matched, on='Username_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username_x</th>\n",
       "      <th>Time (First Post in GA)</th>\n",
       "      <th>Datetime (First Post in GA)</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date (First Post)</th>\n",
       "      <th>Username_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dayquando</td>\n",
       "      <td>1377212671</td>\n",
       "      <td>2013-08-22 16:04:31</td>\n",
       "      <td>442</td>\n",
       "      <td>2013-06-22</td>\n",
       "      <td>abbys23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L15t3r0f5m3g</td>\n",
       "      <td>1377228054</td>\n",
       "      <td>2013-08-22 20:20:54</td>\n",
       "      <td>571</td>\n",
       "      <td>2010-04-26</td>\n",
       "      <td>aDildoAteMyBaby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nakedcows</td>\n",
       "      <td>1378607851</td>\n",
       "      <td>2013-09-07 19:37:31</td>\n",
       "      <td>89</td>\n",
       "      <td>2013-01-19</td>\n",
       "      <td>Atrapenna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>killyourego</td>\n",
       "      <td>1379102885</td>\n",
       "      <td>2013-09-13 13:08:05</td>\n",
       "      <td>450</td>\n",
       "      <td>2012-09-02</td>\n",
       "      <td>AProjection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>killyourego</td>\n",
       "      <td>1379102885</td>\n",
       "      <td>2013-09-13 13:08:05</td>\n",
       "      <td>451</td>\n",
       "      <td>2012-09-02</td>\n",
       "      <td>Ardvarkeating101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>conspiracy_thug</td>\n",
       "      <td>1433999747</td>\n",
       "      <td>2015-06-10 22:15:47</td>\n",
       "      <td>551</td>\n",
       "      <td>2012-03-08</td>\n",
       "      <td>Angelus333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>Icanus</td>\n",
       "      <td>1435087113</td>\n",
       "      <td>2015-06-23 12:18:33</td>\n",
       "      <td>526</td>\n",
       "      <td>2009-04-01</td>\n",
       "      <td>asmosdeus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>kill__all__hippies</td>\n",
       "      <td>1435595912</td>\n",
       "      <td>2015-06-29 09:38:32</td>\n",
       "      <td>431</td>\n",
       "      <td>2015-03-16</td>\n",
       "      <td>Arzu1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>kill__all__hippies</td>\n",
       "      <td>1435595912</td>\n",
       "      <td>2015-06-29 09:38:32</td>\n",
       "      <td>432</td>\n",
       "      <td>2015-03-16</td>\n",
       "      <td>BHOP_TO_NEUROFUNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>evolapatient</td>\n",
       "      <td>1436968777</td>\n",
       "      <td>2015-07-15 06:59:37</td>\n",
       "      <td>586</td>\n",
       "      <td>2015-01-19</td>\n",
       "      <td>13mera7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>564 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Username_x  Time (First Post in GA) Datetime (First Post in GA)  \\\n",
       "0             Dayquando               1377212671         2013-08-22 16:04:31   \n",
       "1          L15t3r0f5m3g               1377228054         2013-08-22 20:20:54   \n",
       "2             nakedcows               1378607851         2013-09-07 19:37:31   \n",
       "3           killyourego               1379102885         2013-09-13 13:08:05   \n",
       "4           killyourego               1379102885         2013-09-13 13:08:05   \n",
       "..                  ...                      ...                         ...   \n",
       "559     conspiracy_thug               1433999747         2015-06-10 22:15:47   \n",
       "560              Icanus               1435087113         2015-06-23 12:18:33   \n",
       "561  kill__all__hippies               1435595912         2015-06-29 09:38:32   \n",
       "562  kill__all__hippies               1435595912         2015-06-29 09:38:32   \n",
       "563        evolapatient               1436968777         2015-07-15 06:59:37   \n",
       "\n",
       "     Unnamed: 0 Date (First Post)         Username_y  \n",
       "0           442        2013-06-22            abbys23  \n",
       "1           571        2010-04-26    aDildoAteMyBaby  \n",
       "2            89        2013-01-19          Atrapenna  \n",
       "3           450        2012-09-02        AProjection  \n",
       "4           451        2012-09-02   Ardvarkeating101  \n",
       "..          ...               ...                ...  \n",
       "559         551        2012-03-08         Angelus333  \n",
       "560         526        2009-04-01          asmosdeus  \n",
       "561         431        2015-03-16           Arzu1982  \n",
       "562         432        2015-03-16  BHOP_TO_NEUROFUNK  \n",
       "563         586        2015-01-19            13mera7  \n",
       "\n",
       "[564 rows x 6 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['Date (First Post in GA)'] = pd.to_datetime(df_merged['Datetime (First Post in GA)']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username_x</th>\n",
       "      <th>Time (First Post in GA)</th>\n",
       "      <th>Datetime (First Post in GA)</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date (First Post)</th>\n",
       "      <th>Username_y</th>\n",
       "      <th>Date (First Post in GA)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dayquando</td>\n",
       "      <td>1377212671</td>\n",
       "      <td>2013-08-22 16:04:31</td>\n",
       "      <td>442</td>\n",
       "      <td>2013-06-22</td>\n",
       "      <td>abbys23</td>\n",
       "      <td>2013-08-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L15t3r0f5m3g</td>\n",
       "      <td>1377228054</td>\n",
       "      <td>2013-08-22 20:20:54</td>\n",
       "      <td>571</td>\n",
       "      <td>2010-04-26</td>\n",
       "      <td>aDildoAteMyBaby</td>\n",
       "      <td>2013-08-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nakedcows</td>\n",
       "      <td>1378607851</td>\n",
       "      <td>2013-09-07 19:37:31</td>\n",
       "      <td>89</td>\n",
       "      <td>2013-01-19</td>\n",
       "      <td>Atrapenna</td>\n",
       "      <td>2013-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>killyourego</td>\n",
       "      <td>1379102885</td>\n",
       "      <td>2013-09-13 13:08:05</td>\n",
       "      <td>450</td>\n",
       "      <td>2012-09-02</td>\n",
       "      <td>AProjection</td>\n",
       "      <td>2013-09-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>killyourego</td>\n",
       "      <td>1379102885</td>\n",
       "      <td>2013-09-13 13:08:05</td>\n",
       "      <td>451</td>\n",
       "      <td>2012-09-02</td>\n",
       "      <td>Ardvarkeating101</td>\n",
       "      <td>2013-09-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>conspiracy_thug</td>\n",
       "      <td>1433999747</td>\n",
       "      <td>2015-06-10 22:15:47</td>\n",
       "      <td>551</td>\n",
       "      <td>2012-03-08</td>\n",
       "      <td>Angelus333</td>\n",
       "      <td>2015-06-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>Icanus</td>\n",
       "      <td>1435087113</td>\n",
       "      <td>2015-06-23 12:18:33</td>\n",
       "      <td>526</td>\n",
       "      <td>2009-04-01</td>\n",
       "      <td>asmosdeus</td>\n",
       "      <td>2015-06-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>kill__all__hippies</td>\n",
       "      <td>1435595912</td>\n",
       "      <td>2015-06-29 09:38:32</td>\n",
       "      <td>431</td>\n",
       "      <td>2015-03-16</td>\n",
       "      <td>Arzu1982</td>\n",
       "      <td>2015-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>kill__all__hippies</td>\n",
       "      <td>1435595912</td>\n",
       "      <td>2015-06-29 09:38:32</td>\n",
       "      <td>432</td>\n",
       "      <td>2015-03-16</td>\n",
       "      <td>BHOP_TO_NEUROFUNK</td>\n",
       "      <td>2015-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>evolapatient</td>\n",
       "      <td>1436968777</td>\n",
       "      <td>2015-07-15 06:59:37</td>\n",
       "      <td>586</td>\n",
       "      <td>2015-01-19</td>\n",
       "      <td>13mera7</td>\n",
       "      <td>2015-07-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>564 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Username_x  Time (First Post in GA) Datetime (First Post in GA)  \\\n",
       "0             Dayquando               1377212671         2013-08-22 16:04:31   \n",
       "1          L15t3r0f5m3g               1377228054         2013-08-22 20:20:54   \n",
       "2             nakedcows               1378607851         2013-09-07 19:37:31   \n",
       "3           killyourego               1379102885         2013-09-13 13:08:05   \n",
       "4           killyourego               1379102885         2013-09-13 13:08:05   \n",
       "..                  ...                      ...                         ...   \n",
       "559     conspiracy_thug               1433999747         2015-06-10 22:15:47   \n",
       "560              Icanus               1435087113         2015-06-23 12:18:33   \n",
       "561  kill__all__hippies               1435595912         2015-06-29 09:38:32   \n",
       "562  kill__all__hippies               1435595912         2015-06-29 09:38:32   \n",
       "563        evolapatient               1436968777         2015-07-15 06:59:37   \n",
       "\n",
       "     Unnamed: 0 Date (First Post)         Username_y Date (First Post in GA)  \n",
       "0           442        2013-06-22            abbys23              2013-08-22  \n",
       "1           571        2010-04-26    aDildoAteMyBaby              2013-08-22  \n",
       "2            89        2013-01-19          Atrapenna              2013-09-07  \n",
       "3           450        2012-09-02        AProjection              2013-09-13  \n",
       "4           451        2012-09-02   Ardvarkeating101              2013-09-13  \n",
       "..          ...               ...                ...                     ...  \n",
       "559         551        2012-03-08         Angelus333              2015-06-10  \n",
       "560         526        2009-04-01          asmosdeus              2015-06-23  \n",
       "561         431        2015-03-16           Arzu1982              2015-06-29  \n",
       "562         432        2015-03-16  BHOP_TO_NEUROFUNK              2015-06-29  \n",
       "563         586        2015-01-19            13mera7              2015-07-15  \n",
       "\n",
       "[564 rows x 7 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_words = pd.read_csv(r'D:/ISI REU Python/coontown-manually-filtered-hate-words.csv')\n",
    "hate_words.columns = ['Hate Words']\n",
    "\n",
    "hate_words = hate_words['Hate Words'].tolist()\n",
    "hate_words = list(set(hate_words) - set(['nigs','sheboons','groids','kikes','coons','niggers','faggots']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_counter(author, post):\n",
    "    hateword_counter = 0\n",
    "#     counter = 0\n",
    "#     global df_in\n",
    "#     global df_out\n",
    "#     df_in = pd.DataFrame(columns=[\"Username\",\"Time\",'chimpout', 'dey', 'negroes', 'whitey', 'sheboon', 'nuffin', 'coon', 'groid', 'gibs', 'nig', 'tnb', 'faggot', 'ghetto', 'dindu', 'kike'])\n",
    "#     df_out = pd.DataFrame(columns=[\"Username\",\"Time\",'chimpout', 'dey', 'negroes', 'whitey', 'sheboon', 'nuffin', 'coon', 'groid', 'gibs', 'nig', 'tnb', 'faggot', 'ghetto', 'dindu', 'kike'])\n",
    "    \n",
    "    if post == 'submission':\n",
    "        if new_line['title'] != None:\n",
    "            hateword_counter += new_line['title'].count('chimpout')\n",
    "            hateword_counter += new_line['title'].count('dey')\n",
    "            hateword_counter += new_line['title'].count('negroes')\n",
    "            hateword_counter += new_line['title'].count('whitey')\n",
    "            hateword_counter += new_line['title'].count('sheboon')\n",
    "            hateword_counter += new_line['title'].count('nuffin')\n",
    "            hateword_counter += new_line['title'].count('coon')\n",
    "            hateword_counter += new_line['title'].count('groid')\n",
    "            hateword_counter += new_line['title'].count('gibs')\n",
    "            hateword_counter += new_line['title'].count('nig')\n",
    "            hateword_counter += new_line['title'].count('tnb')\n",
    "            hateword_counter += new_line['title'].count('faggot')\n",
    "            hateword_counter += new_line['title'].count('ghetto')\n",
    "            hateword_counter += new_line['title'].count('dindu')\n",
    "            hateword_counter += new_line['title'].count('kike')\n",
    "#             counter += len(new_line['title'].split())\n",
    "        if new_line['selftext'] != None:\n",
    "            hateword_counter += new_line['selftext'].count('chimpout')\n",
    "            hateword_counter += new_line['selftext'].count('dey')\n",
    "            hateword_counter += new_line['selftext'].count('negroes')\n",
    "            hateword_counter += new_line['selftext'].count('whitey')\n",
    "            hateword_counter += new_line['selftext'].count('sheboon')\n",
    "            hateword_counter += new_line['selftext'].count('nuffin')\n",
    "            hateword_counter += new_line['selftext'].count('coon')\n",
    "            hateword_counter += new_line['selftext'].count('groid')\n",
    "            hateword_counter += new_line['selftext'].count('gibs')\n",
    "            hateword_counter += new_line['selftext'].count('nig')\n",
    "            hateword_counter += new_line['selftext'].count('tnb')\n",
    "            hateword_counter += new_line['selftext'].count('faggot')\n",
    "            hateword_counter += new_line['selftext'].count('ghetto')\n",
    "            hateword_counter += new_line['selftext'].count('dindu')\n",
    "            hateword_counter += new_line['selftext'].count('kike')\n",
    "#             counter += len(new_line['selftext'].split())\n",
    "#         if new_line['subreddit'] == subreddit:\n",
    "#         if 'created_utc' in new_line.keys():\n",
    "#             df_in = df_in.append({\"Username\":author,\"Time\":datetime.datetime.fromtimestamp(new_line['created_utc']),\"Hate Words\":hateword_counter},ignore_index=True)\n",
    "#         else:\n",
    "#             if 'created_utc' in new_line.keys():\n",
    "#                 df_out = df_out.append({\"Username\":author,\"Time\":datetime.datetime.fromtimestamp(new_line['created_utc']),\"Hate Words\":hateword_counter},ignore_index=True)\n",
    "    if post == 'comment':\n",
    "        if new_line['body'] != None:\n",
    "            hateword_counter += new_line['body'].count('chimpout')\n",
    "            hateword_counter += new_line['body'].count('dey')\n",
    "            hateword_counter += new_line['body'].count('negroes')\n",
    "            hateword_counter += new_line['body'].count('whitey')\n",
    "            hateword_counter += new_line['body'].count('sheboon')\n",
    "            hateword_counter += new_line['body'].count('nuffin')\n",
    "            hateword_counter += new_line['body'].count('coon')\n",
    "            hateword_counter += new_line['body'].count('groid')\n",
    "            hateword_counter += new_line['body'].count('gibs')\n",
    "            hateword_counter += new_line['body'].count('nig')\n",
    "            hateword_counter += new_line['body'].count('tnb')\n",
    "            hateword_counter += new_line['body'].count('faggot')\n",
    "            hateword_counter += new_line['body'].count('ghetto')\n",
    "            hateword_counter += new_line['body'].count('dindu')\n",
    "            hateword_counter += new_line['body'].count('kike')\n",
    "#             counter += len(new_line['body'].split())\n",
    "#         if new_line['subreddit'] == subreddit:\n",
    "#             if 'created_utc' in new_line.keys():\n",
    "#                 df_in = df_in.append({\"Username\":author,\"Time\":datetime.datetime.fromtimestamp(new_line['created_utc']),\"Hate Words\":hateword_counter},ignore_index=True)\n",
    "#         else:\n",
    "#             if 'created_utc' in new_line.keys():\n",
    "#                 df_out = df_out.append({\"Username\":author,\"Time\":datetime.datetime.fromtimestamp(new_line['created_utc']),\"Hate Words\":hateword_counter},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_author = pd.DataFrame(columns = ['Username','Total Score','Total Posts','Average Hate Words'])\n",
    "# df_author.to_csv(r'D:/ISI REU Python/Analyzed Data/Author Data/control_details.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Created UTC  Num Hate Words\n",
      "0   1.348671e+09             NaN\n",
      "1   1.358093e+09             NaN\n",
      "2   1.378681e+09             NaN\n",
      "3   1.240718e+09             NaN\n",
      "4   1.345524e+09             NaN\n",
      "5   1.345843e+09             NaN\n",
      "6   1.345843e+09             NaN\n",
      "7   1.346044e+09             NaN\n",
      "8   1.349880e+09             NaN\n",
      "9   1.353190e+09             NaN\n",
      "10  1.371443e+09             NaN\n",
      "11  1.371444e+09             NaN\n",
      "12  1.371444e+09             NaN\n",
      "13  1.377233e+09             NaN\n",
      "14  1.377233e+09             NaN\n",
      "15  1.377234e+09             NaN\n",
      "16  1.377285e+09             NaN\n",
      "17  1.377320e+09             NaN\n",
      "18  1.377748e+09             NaN\n",
      "19  1.378688e+09             NaN\n",
      "20  1.378689e+09             NaN\n",
      "21  1.378690e+09             NaN\n",
      "22  1.379697e+09             NaN\n",
      "23  1.379703e+09             NaN\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No axis named 1 for object type <class 'pandas.core.series.Series'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-dd64a7d4ea32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;31m#     exec('''df_'''+author_''' = df_'''+author+'''.groupby('Created UTC').mean()''')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Created UTC'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mavg_hate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Num Hate Words'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[0mdf_author\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Username'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mauthor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Total Score'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Total Posts'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtotal_posts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Average Hate Words'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mavg_hate\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mstat_func\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11212\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11213\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_agg_by_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 11214\u001b[1;33m         return self._reduce(\n\u001b[0m\u001b[0;32m  11215\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11216\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   3867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3868\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3869\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3871\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_axis_number\u001b[1;34m(cls, axis)\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"No axis named {axis} for object type {cls}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No axis named 1 for object type <class 'pandas.core.series.Series'>"
     ]
    }
   ],
   "source": [
    "for author in hate_users:\n",
    "    score = 0\n",
    "    total_posts = 0\n",
    "    \n",
    "    df = pd.DataFrame(columns = ['Created UTC','Num Hate Words'])\n",
    "#     exec('''df_'''+author+''' = pd.DataFrame(columns = ['Created UTC','Num Hate Words'])''')\n",
    "    \n",
    "    first_index = df_merged.index[df_merged['Username_y'] == author].tolist()\n",
    "    for i in first_index:\n",
    "        int_first = int(i)\n",
    "        break\n",
    "    \n",
    "    file_name = \"D:/ISI REU Python/Authors PSAW (Copy)/\"+author+\"_submissions.json\"\n",
    "    with open(file_name,'r') as json_file:\n",
    "        for line in json_file:\n",
    "            created_utc = []\n",
    "            new_line = json.loads(line)\n",
    "            if int(new_line['created_utc']) < int(df_merged['Time (First Post in GA)'].loc[int_first]):\n",
    "#                 print('yes')\n",
    "                score += int(new_line['score'])\n",
    "                total_posts += 1\n",
    "#                 created_utc.append(new_line['created_utc'])  # to eventually calculate posts per day\n",
    "                hate = word_counter(author,'submission')\n",
    "                \n",
    "                df = df.append({'Created UTC':new_line['created_utc'],'Num Hate Words':hate},ignore_index=True)\n",
    "            \n",
    "    file_name = \"D:/ISI REU Python/Authors PSAW (Copy)/\"+author+\"_comments.json\"\n",
    "    with open(file_name,'r') as json_file:\n",
    "        for line in json_file:\n",
    "            created_utc = []\n",
    "            new_line = json.loads(line)\n",
    "            if int(new_line['created_utc']) < int(df_merged['Time (First Post in GA)'].loc[int_first]):\n",
    "#                 print('yes')\n",
    "                score += int(new_line['score'])\n",
    "                total_posts += 1\n",
    "#                 created_utc.append(new_line['created_utc'])  # to eventually calculate posts per day\n",
    "                hate = word_counter(author,'comment')\n",
    "                \n",
    "                df = df.append({'Created UTC':new_line['created_utc'],'Num Hate Words':hate},ignore_index=True)\n",
    "            \n",
    "    print(df)\n",
    "    \n",
    "#     exec('''total_score = df_'''+author+'''['Score'].sum(axis=1)''')\n",
    "#     exec('''all_total_posts = df_'''+author+'''['Total Posts'].sum(axis=1)''')\n",
    "#     exec('''df_'''+author_''' = df_'''+author+'''.groupby('Created UTC').mean()''')\n",
    "    df = df.groupby('Created UTC').mean()\n",
    "    avg_hate = df['Num Hate Words'].mean(axis=1)\n",
    "    df_author = pd.DataFrame({'Username':author,'Total Score':score,'Total Posts':total_posts,'Average Hate Words':avg_hate})\n",
    "    \n",
    "    new_file_name = r'D:/ISI REU Python/Analyzed Data/Author Data/control_details.csv'\n",
    "    df_author.to_csv(new_file_name,mode='a',header=None)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Created UTC</th>\n",
       "      <th>Num Hate Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Created UTC, Num Hate Words]\n",
       "Index: []"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
